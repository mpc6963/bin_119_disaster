{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f6349f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-06T07:29:58.734424Z",
     "iopub.status.busy": "2024-08-06T07:29:58.733724Z",
     "iopub.status.idle": "2024-08-06T07:29:59.444446Z",
     "shell.execute_reply": "2024-08-06T07:29:59.443439Z"
    },
    "papermill": {
     "duration": 0.716656,
     "end_time": "2024-08-06T07:29:59.446706",
     "exception": false,
     "start_time": "2024-08-06T07:29:58.730050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/119-csv/VL.csv\n",
      "/kaggle/input/119-csv/TL.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b937eaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T07:29:59.452820Z",
     "iopub.status.busy": "2024-08-06T07:29:59.452364Z",
     "iopub.status.idle": "2024-08-06T07:31:45.445323Z",
     "shell.execute_reply": "2024-08-06T07:31:45.444397Z"
    },
    "papermill": {
     "duration": 105.998412,
     "end_time": "2024-08-06T07:31:45.447489",
     "exception": false,
     "start_time": "2024-08-06T07:29:59.449077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 07:30:06.628346: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 07:30:06.628476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 07:30:06.762858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1ad9b7d7e54df98313e2c7064a809f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3388c8e0ed314e0fae262249511a2c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/504 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764aef89374a485faa1966779130cacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/450k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86038e6c9bd9417dad932e9584283915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a484f089984cefa527fc708bb14945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba0fd65f131456e80cf47b028e97f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/127178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4901b78cf6f4d2ca673fab9d9328a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# ÏÑ§Ï†ï ÌååÏùº ÏùΩÍ∏∞\n",
    "config = {\n",
    "    \"task\": \"disaster\",\n",
    "    \"data_dir\": \"/kaggle/input/119-csv\",\n",
    "    \"ckpt_dir\": \"./ckpt_dir\",\n",
    "    \"train_file\": \"/TL.csv\",\n",
    "    \"dev_file\": False,\n",
    "    \"test_file\": \"/VL.csv\",\n",
    "    \"evaluate_test_during_training\": True,\n",
    "    \"eval_all_checkpoints\": True,\n",
    "    \"save_optimizer\": True,\n",
    "    \"do_lower_case\": False,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"max_seq_len\": 512,\n",
    "    \"num_train_epochs\": 30,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_proportion\": 0,\n",
    "    \"max_steps\": -1,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"model_type\": \"Auto\",\n",
    "    \"model_name_or_path\": \"beomi/KcELECTRA-base-v2022\",\n",
    "    \"tokenizer_path\": \"beomi/KcELECTRA-base-v2022\",\n",
    "    \"log_dir\": \"/kaggle/working/log_path\",\n",
    "    \"log_file\": \"train_log.log\",\n",
    "    \"output_dir\": \"/kaggle/working/finetuned_models/disasterLarge\",\n",
    "    \"seed\": 42,\n",
    "    \"train_batch_size\": 16,  # Î∞∞Ïπò ÌÅ¨Í∏∞Î•º Ï§ÑÏûÑ\n",
    "    \"eval_batch_size\": 32,  # Î∞∞Ïπò ÌÅ¨Í∏∞Î•º Ï§ÑÏûÑ\n",
    "    \"logging_steps\": 1000,\n",
    "    \"save_steps\": 1000,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"fp16\": True  # Mixed Precision Training ÌôúÏÑ±Ìôî\n",
    "}\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "train_data = pd.read_csv('/kaggle/input/119-csv/TL.csv')\n",
    "val_data = pd.read_csv('/kaggle/input/119-csv/VL.csv')\n",
    "\n",
    "# 'disasterMedium' Ïó¥Ïùò Í≥†Ïú†Ìïú Î∂ÑÎ•ò Ïù¥Î¶ÑÏùÑ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "unique_labels = train_data['disasterLarge'].unique()\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# ÎùºÎ≤®ÏùÑ Ïà´ÏûêÎ°ú Î≥ÄÌôò\n",
    "train_data['label'] = train_data['disasterLarge'].map(label_map)\n",
    "val_data['label'] = val_data['disasterLarge'].map(label_map)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÏôÄ Î™®Îç∏ Î°úÎìú\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['tokenizer_path'])\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config['model_name_or_path'], num_labels=len(unique_labels))\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï Ìï®Ïàò\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=config['max_seq_len'])\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Î∂àÌïÑÏöîÌïú Ïó¥ Ï†úÍ±∞\n",
    "train_dataset = train_dataset.remove_columns(['disasterMedium', 'urgencyLevel', 'sentiment', 'symptom', 'triage'])\n",
    "val_dataset = val_dataset.remove_columns(['disasterMedium', 'urgencyLevel', 'sentiment', 'symptom', 'triage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cffa638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T07:31:45.456495Z",
     "iopub.status.busy": "2024-08-06T07:31:45.455743Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-08-06T07:31:45.451246",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35418' max='238470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 35418/238470 11:58:15 < 68:37:58, 0.82 it/s, Epoch 4.46/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.325531</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.905833</td>\n",
       "      <td>0.910381</td>\n",
       "      <td>0.914072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.322631</td>\n",
       "      <td>0.908977</td>\n",
       "      <td>0.899342</td>\n",
       "      <td>0.911787</td>\n",
       "      <td>0.908977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.378573</td>\n",
       "      <td>0.900421</td>\n",
       "      <td>0.885106</td>\n",
       "      <td>0.879673</td>\n",
       "      <td>0.900421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.791266</td>\n",
       "      <td>0.756180</td>\n",
       "      <td>0.651196</td>\n",
       "      <td>0.571809</td>\n",
       "      <td>0.756180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data Collator ÏÉùÏÑ±\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# ÌèâÍ∞Ä Î©îÌä∏Î¶≠ Ìï®Ïàò Ï†ïÏùò\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Trainer ÏÑ§Ï†ï\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config['output_dir'],\n",
    "    evaluation_strategy=\"epoch\" if config['do_eval'] else \"no\",\n",
    "    save_strategy=\"epoch\",  # save_strategyÎ•º epochÎ°ú ÏÑ§Ï†ï\n",
    "    learning_rate=config['learning_rate'],\n",
    "    per_device_train_batch_size=config['train_batch_size'],\n",
    "    per_device_eval_batch_size=config['eval_batch_size'],\n",
    "    num_train_epochs=config['num_train_epochs'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    logging_dir=config['log_dir'],\n",
    "    logging_steps=config['logging_steps'],\n",
    "    save_steps=config['save_steps'],\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=3,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=[],  # Î≥¥Í≥†Ìï† Î°úÍ∑∏ ÏÑúÎπÑÏä§ ÏÑ§Ï†ï\n",
    "    fp16=config['fp16'],  # Mixed Precision Training ÌôúÏÑ±Ìôî\n",
    "    gradient_checkpointing=True  # Gradient Checkpointing ÌôúÏÑ±Ìôî\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics  # compute_metrics Ï∂îÍ∞Ä\n",
    ")\n",
    "\n",
    "# Î™®Îç∏ ÌïôÏäµ\n",
    "if config['do_train']:\n",
    "    trainer.train()\n",
    "\n",
    "# Î™®Îç∏ ÌèâÍ∞Ä\n",
    "if config['do_eval']:\n",
    "    evaluation_results = trainer.evaluate()\n",
    "    print(evaluation_results)\n",
    "\n",
    "# ÌïôÏäµÎêú Î™®Îç∏ Ï†ÄÏû•\n",
    "trainer.save_model(config['output_dir'])\n",
    "tokenizer.save_pretrained(config['output_dir'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5370161,
     "sourceId": 8927615,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 186292475,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-06T07:29:55.810637",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}