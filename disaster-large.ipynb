{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f6349f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-06T07:29:58.734424Z",
     "iopub.status.busy": "2024-08-06T07:29:58.733724Z",
     "iopub.status.idle": "2024-08-06T07:29:59.444446Z",
     "shell.execute_reply": "2024-08-06T07:29:59.443439Z"
    },
    "papermill": {
     "duration": 0.716656,
     "end_time": "2024-08-06T07:29:59.446706",
     "exception": false,
     "start_time": "2024-08-06T07:29:58.730050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/119-csv/VL.csv\n",
      "/kaggle/input/119-csv/TL.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b937eaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T07:29:59.452820Z",
     "iopub.status.busy": "2024-08-06T07:29:59.452364Z",
     "iopub.status.idle": "2024-08-06T07:31:45.445323Z",
     "shell.execute_reply": "2024-08-06T07:31:45.444397Z"
    },
    "papermill": {
     "duration": 105.998412,
     "end_time": "2024-08-06T07:31:45.447489",
     "exception": false,
     "start_time": "2024-08-06T07:29:59.449077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 07:30:06.628346: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 07:30:06.628476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 07:30:06.762858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1ad9b7d7e54df98313e2c7064a809f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3388c8e0ed314e0fae262249511a2c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/504 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764aef89374a485faa1966779130cacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/450k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86038e6c9bd9417dad932e9584283915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a484f089984cefa527fc708bb14945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba0fd65f131456e80cf47b028e97f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/127178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4901b78cf6f4d2ca673fab9d9328a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 설정 파일 읽기\n",
    "config = {\n",
    "    \"task\": \"disaster\",\n",
    "    \"data_dir\": \"/kaggle/input/119-csv\",\n",
    "    \"ckpt_dir\": \"./ckpt_dir\",\n",
    "    \"train_file\": \"/TL.csv\",\n",
    "    \"dev_file\": False,\n",
    "    \"test_file\": \"/VL.csv\",\n",
    "    \"evaluate_test_during_training\": True,\n",
    "    \"eval_all_checkpoints\": True,\n",
    "    \"save_optimizer\": True,\n",
    "    \"do_lower_case\": False,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"max_seq_len\": 512,\n",
    "    \"num_train_epochs\": 30,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_proportion\": 0,\n",
    "    \"max_steps\": -1,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"model_type\": \"Auto\",\n",
    "    \"model_name_or_path\": \"beomi/KcELECTRA-base-v2022\",\n",
    "    \"tokenizer_path\": \"beomi/KcELECTRA-base-v2022\",\n",
    "    \"log_dir\": \"/kaggle/working/log_path\",\n",
    "    \"log_file\": \"train_log.log\",\n",
    "    \"output_dir\": \"/kaggle/working/finetuned_models/disasterLarge\",\n",
    "    \"seed\": 42,\n",
    "    \"train_batch_size\": 16,  # 배치 크기를 줄임\n",
    "    \"eval_batch_size\": 32,  # 배치 크기를 줄임\n",
    "    \"logging_steps\": 1000,\n",
    "    \"save_steps\": 1000,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"fp16\": True  # Mixed Precision Training 활성화\n",
    "}\n",
    "\n",
    "# 데이터 로드\n",
    "train_data = pd.read_csv('/kaggle/input/119-csv/TL.csv')\n",
    "val_data = pd.read_csv('/kaggle/input/119-csv/VL.csv')\n",
    "\n",
    "# 'disasterMedium' 열의 고유한 분류 이름을 가져오기\n",
    "unique_labels = train_data['disasterLarge'].unique()\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# 라벨을 숫자로 변환\n",
    "train_data['label'] = train_data['disasterLarge'].map(label_map)\n",
    "val_data['label'] = val_data['disasterLarge'].map(label_map)\n",
    "\n",
    "# 데이터셋 객체 생성\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# 토크나이저와 모델 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['tokenizer_path'])\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config['model_name_or_path'], num_labels=len(unique_labels))\n",
    "\n",
    "# 데이터셋 토크나이징 함수\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=config['max_seq_len'])\n",
    "\n",
    "# 데이터셋 토크나이징\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "train_dataset = train_dataset.remove_columns(['disasterMedium', 'urgencyLevel', 'sentiment', 'symptom', 'triage'])\n",
    "val_dataset = val_dataset.remove_columns(['disasterMedium', 'urgencyLevel', 'sentiment', 'symptom', 'triage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cffa638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T07:31:45.456495Z",
     "iopub.status.busy": "2024-08-06T07:31:45.455743Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-08-06T07:31:45.451246",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35418' max='238470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 35418/238470 11:58:15 < 68:37:58, 0.82 it/s, Epoch 4.46/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.325531</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.905833</td>\n",
       "      <td>0.910381</td>\n",
       "      <td>0.914072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.322631</td>\n",
       "      <td>0.908977</td>\n",
       "      <td>0.899342</td>\n",
       "      <td>0.911787</td>\n",
       "      <td>0.908977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.378573</td>\n",
       "      <td>0.900421</td>\n",
       "      <td>0.885106</td>\n",
       "      <td>0.879673</td>\n",
       "      <td>0.900421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.791266</td>\n",
       "      <td>0.756180</td>\n",
       "      <td>0.651196</td>\n",
       "      <td>0.571809</td>\n",
       "      <td>0.756180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data Collator 생성\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# 평가 메트릭 함수 정의\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Trainer 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config['output_dir'],\n",
    "    evaluation_strategy=\"epoch\" if config['do_eval'] else \"no\",\n",
    "    save_strategy=\"epoch\",  # save_strategy를 epoch로 설정\n",
    "    learning_rate=config['learning_rate'],\n",
    "    per_device_train_batch_size=config['train_batch_size'],\n",
    "    per_device_eval_batch_size=config['eval_batch_size'],\n",
    "    num_train_epochs=config['num_train_epochs'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    logging_dir=config['log_dir'],\n",
    "    logging_steps=config['logging_steps'],\n",
    "    save_steps=config['save_steps'],\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=3,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=[],  # 보고할 로그 서비스 설정\n",
    "    fp16=config['fp16'],  # Mixed Precision Training 활성화\n",
    "    gradient_checkpointing=True  # Gradient Checkpointing 활성화\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics  # compute_metrics 추가\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "if config['do_train']:\n",
    "    trainer.train()\n",
    "\n",
    "# 모델 평가\n",
    "if config['do_eval']:\n",
    "    evaluation_results = trainer.evaluate()\n",
    "    print(evaluation_results)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "trainer.save_model(config['output_dir'])\n",
    "tokenizer.save_pretrained(config['output_dir'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5370161,
     "sourceId": 8927615,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 186292475,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-06T07:29:55.810637",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}